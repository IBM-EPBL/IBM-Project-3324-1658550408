{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kSaU3gp0C3K"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-R0i12O0IIJ",
        "outputId": "05e8206d-b8c0-40f9-d4cb-9cace275c2d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15770 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "x_train = train_datagen.flow_from_directory(r'/content/drive/MyDrive/conversation engine for deaf and dumb/Dataset/training_set',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode=\"grayscale\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBPYDt5r0N5b",
        "outputId": "24fb2b67-afe5-4d12-d158-fcec8c44ad7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2250 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "x_test = test_datagen.flow_from_directory(r'/content/drive/MyDrive/conversation engine for deaf and dumb/Dataset/test_set',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode=\"grayscale\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdYva81c0Xhu"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJFt4Jia0c7z"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hJAgD-_0jq1"
      },
      "outputs": [],
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(64,64,1), activation='relu'))\n",
        "#no. of feature detectors, size of feature detector, image size, activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJt9APHF0uHd"
      },
      "outputs": [],
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deDYUMzb0zqE"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fj1zu5W05DR"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units=512, activation = 'relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqKCsFDV09jq"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units=9,  activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqu2Irm81DNJ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMEAHvgb1PRB",
        "outputId": "629e0836-cad1-48a2-ff1d-f134abc78e7b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.5017 - accuracy: 0.6271  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2218s 93s/step - loss: 1.5017 - accuracy: 0.6271 - val_loss: 0.5051 - val_accuracy: 0.8644\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 754s 31s/step - loss: 0.3132 - accuracy: 0.9147\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 479s 20s/step - loss: 0.1686 - accuracy: 0.9550\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 241s 10s/step - loss: 0.1068 - accuracy: 0.9729\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 121s 5s/step - loss: 0.0740 - accuracy: 0.9827\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 70s 3s/step - loss: 0.0563 - accuracy: 0.9856\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 46s 2s/step - loss: 0.0444 - accuracy: 0.9878\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 35s 1s/step - loss: 0.0349 - accuracy: 0.9922\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 31s 1s/step - loss: 0.0274 - accuracy: 0.9951\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0234 - accuracy: 0.9945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0889353f10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=24,epochs=10,validation_data = x_test, validation_steps= 40)\n",
        "#steps_per_epoch = no. of train images//batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Zh2HwAp61Qz1"
      },
      "outputs": [],
      "source": [
        "model.save('aslpng1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MM1EOA4J1cJi"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "boVVAgD11ghr"
      },
      "outputs": [],
      "source": [
        "model=load_model('aslpng1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zvmdsDi11pKK"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "def detect(frame):\n",
        "  img = resize(frame,(64,64,1))\n",
        "  img = np.expand_dims(img,axis=0)\n",
        "  if(np.max(img)>1):\n",
        "    img = img/255.0\n",
        "  prediction = model.predict(img)\n",
        "  print(prediction)\n",
        "  prediction = np.argmax(prediction,axis=1)\n",
        "  print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkJtbObN1uVn",
        "outputId": "f27826d8-bbc1-41b7-df22-765b6f3ff0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n",
            "[[9.8879457e-01 4.7520574e-09 3.4719829e-08 2.1185616e-07 1.1017337e-02\n",
            "  1.3071556e-06 4.0822721e-05 2.1473575e-08 1.4569308e-04]]\n",
            "[0]\n"
          ]
        }
      ],
      "source": [
        "frame=cv2.imread(r'/content/drive/MyDrive/conversation engine for deaf and dumb/Dataset/test_set/A/1.png')\n",
        "data = detect(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0vgAqC62EHJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}